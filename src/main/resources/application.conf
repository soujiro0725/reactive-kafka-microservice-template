http {
  host = "0.0.0.0",
  //port = 8080
}

akka {
  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "ERROR"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  //stdout-loglevel = "DEBUG"

  # Filter of log events that is used by the LoggingAdapter before
  # publishToKafka log events to the eventStream.
  logging-filter = "akka.event.DefaultLoggingFilter"

  #Dead-letter logging settings
  #log-dead-letters = off
  #log-dead-letters-during-shutdown = off

  kinesis {

    application-name = "reactive-kinesis-microservice-template"

    # The name of the this producer, we can have many producers per application.
    # MUST contain the stream-name as a minimum. Any additional settings defined will override
    # defaults in the kinesis.producer reference.conf for this producer only.
    data-producer {
      # The name of the producer stream
      stream-name = "TestDataChannel"

      kpl {
        Region = ap-northeast-1
      }
    }

    event-producer {
      # The name of the producer stream
      stream-name = "AppEventChannel"

      kpl {
        Region = ap-northeast-1
      }
    }

   # The name of the consumer, we can have many consumers per application
   data-consumer {
      # The name of the consumer stream, MUST be specified per consumer and MUST exist
      stream-name = "TestDataChannel"
    }
   
    event-consumer {
      stream-name = "AppEventChannel"
    }
  }

  kafka {
    # Properties for akka.kafka.ConsumerSettings can be
    # defined in this section or a configuration section with
    # the same layout.
    consumer {

      //The number of unique Kafka consumers consuming from individual topics
      num-consumers = "2"
      c1 {
        bootstrap-servers = "localhost:9092"
        groupId = "group1"
        subscription-topic = "TestDataChannel"

        #MessageType to convert internal case class from to JSON
        message-type = "KafkaMessage"

        # Tuning property of scheduled polls.
        poll-interval = 50ms

        # Tuning property of the `KafkaConsumer.poll` parameter.
        # Note that non-zero value means that blocking of the thread that
        # is executing the stage will be blocked.
        poll-timeout = 50ms

        # The stage will be await outstanding offset commit requests before
        # shutting down, but if that takes longer than this timeout it will
        # stop forcefully.
        stop-timeout = 30s

        # How long to wait for `KafkaConsumer.close`
        close-timeout = 20s

        # If offset commit requests are not completed within this timeout
        # the returned Future is completed `TimeoutException`.
        commit-timeout = 15s

        # If the KafkaConsumer can't connect to the broker the poll will be
        # aborted after this timeout. The KafkaConsumerActor will throw
        # org.apache.kafka.common.errors.WakeupException, which can be handled
        # with Actor supervision strategy.
        wakeup-timeout = 10s

        # Fully qualified config path which holds the dispatcher configuration
        # to be used by the KafkaConsumerActor. Some blocking may occur.
        use-dispatcher = "akka.kafka.default-dispatcher"

        # Properties defined by org.apache.kafka.clients.consumers.ConsumerConfig
        # can be defined in this configuration section.
        kafka-clients {
          enable.auto.commit = false
          #auto.commit.interval.ms = 10000
        }
      }

      c2 {
        bootstrap-servers = "localhost:9092"
        groupId = "group2"
        subscription-topic = "AppEventChannel"
        message-type = "ExampleAppEvent"
        poll-interval = 50ms
        poll-timeout = 50ms
        stop-timeout = 30s
        close-timeout = 20s
        commit-timeout = 15s
        wakeup-timeout = 10s
        use-dispatcher = "akka.kafka.default-dispatcher"
        kafka-clients {
          enable.auto.commit = false
          #auto.commit.interval.ms = 10000
        }
      }
    }

    # Properties for akka.kafka.ProducerSettings can be
    # defined in this section or a configuration section with
    # the same layout.
    producer {
      //The number of unique Kafka producers producing to individual topics
      num-producers = "2"

      p1 {
        bootstrap-servers = "localhost:9092"
        publish-topic = "TestDataChannel"

        #MessageType to convert internal case class from to JSON
        message-type = "KafkaMessage"

        # Tuning parameter of how many sends that can run in parallel.
        parallelism = 100

        # How long to wait for `KafkaProducer.close`
        close-timeout = 60s

        # Fully qualified config path which holds the dispatcher configuration
        # to be used by the producers stages. Some blocking may occur.
        # When this value is empty, the dispatcher configured for the stream
        # will be used.
        use-dispatcher = "akka.kafka.default-dispatcher"

        request.required.acks = "1"
        //Below is necessary for having multiple consumers consume the same topic
        //num.partitions has to be geq num of consumers
        //auto.offset.reset = "smallest"
        num.partitions = "5"
      }

      p2 {
        bootstrap-servers = "localhost:9092"
        message-type = "ExampleAppEvent"
        publish-topic = "AppEventChannel"
        parallelism = 100
        close-timeout = 60s
        use-dispatcher = "akka.kafka.default-dispatcher"
        request.required.acks = "1"
        num.partitions = "5"
      }
    }
  }
}
